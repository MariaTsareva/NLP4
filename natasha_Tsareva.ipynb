{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER - Natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natasha  - питоновская библиотека для извлечения именованных сущностей. Она похоже на Tomita-parser, но в ней все на чистом питоне, с открытым кодом и активно развивается. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если быть точнее, то natasha - набор готовых правил для парсера yargy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть например готовые правила для извлечения персон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установить можно через pip.\n",
    "from natasha import NamesExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = open('sents.txt', encoding='utf-8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = NamesExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что извлекается не очень хорошо. К тому же в реальной задаче нам потребуется извлекать ещё какие-то аттрибуты сущностей и группировать их в факты. И не обязательно этих типов. Поэтому полезно разобраться с самим парсером yargy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документация yargy: https://yargy.readthedocs.io/ru/latest/reference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего с такими штуками разбираться на практике. Давайте попробуем написать правила для извлечения персон. Каждая персона должна описываться 3 полями - Имя, Фамилия, Отчество. Также у Персоны должны быть атрибуты - должность и место работы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За основу возьмем пример из документации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy import Parser, rule, or_\n",
    "from yargy.predicates import gram\n",
    "from yargy.pipelines import morph_pipeline\n",
    "from yargy.interpretation import fact\n",
    "from IPython.display import display\n",
    "\n",
    "Person = fact(\n",
    "    'Person',\n",
    "    ['position', 'name']\n",
    ")\n",
    "Name = fact(\n",
    "    'Name',\n",
    "    ['first', 'last']\n",
    ")\n",
    "\n",
    "\n",
    "POSITION = morph_pipeline([\n",
    "    'премьер министр',\n",
    "    'президент'\n",
    "])\n",
    "\n",
    "NAME = rule(\n",
    "    gram('Name').interpretation(\n",
    "        Name.first.inflected()\n",
    "    ),\n",
    "    gram('Surn').interpretation(\n",
    "        Name.last.inflected()\n",
    "    )\n",
    ").interpretation(\n",
    "    Name\n",
    ")\n",
    "\n",
    "PERSON = rule(\n",
    "    POSITION.interpretation(\n",
    "        Person.position.inflected()\n",
    "    ),\n",
    "    NAME.interpretation(\n",
    "        Person.name\n",
    "    )\n",
    ").interpretation(\n",
    "    Person\n",
    ")\n",
    "\n",
    "\n",
    "parser = Parser(PERSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in sents[:100]:\n",
    "#     print(sent)\n",
    "#     for match in parser.findall(sent):\n",
    "#         display(match.fact)\n",
    "#     print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы проверить какие морфологические тэги приписываются словам, можно использовать MorphTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy.tokenizer import MorphTokenizer\n",
    "tokenizer = MorphTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MorphToken('Медведев',\n",
       "            [0, 8),\n",
       "            'RU',\n",
       "            [Form('медведев', Grams(NOUN,Sgtm,Surn,anim,masc,nomn,sing))])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer('Медведев'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача на семинар:\n",
    "Доработать правила так, чтобы извлекалось как можно больше правильных фактов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Person = fact(\n",
    "    'Person',\n",
    "    ['position', 'name', 'place']\n",
    ")\n",
    "Name = fact(\n",
    "    'Name',\n",
    "    ['first', 'last', 'patronymic']\n",
    ")\n",
    "\n",
    "\n",
    "POSITION = morph_pipeline([\n",
    "    'премьер министр',\n",
    "    'президент',\n",
    "    'премьер-министр',\n",
    "    'министр',\n",
    "    'вице-премьер',\n",
    "    'премьер',\n",
    "    'министр финансов',\n",
    "    'политик',\n",
    "    'министр внутренних дел',\n",
    "    'министр обороны',\n",
    "    'министр культуры',\n",
    "    'пресс-сектретарь',\n",
    "    'канцлер',\n",
    "    'председатель'\n",
    "])\n",
    "\n",
    "NAME = or_(\n",
    "    rule(\n",
    "    gram('Name').interpretation(\n",
    "        Name.first.inflected()\n",
    "    ),\n",
    "    gram('Surn').interpretation(\n",
    "        Name.last.inflected()\n",
    "    ),\n",
    "    gram('Patr').interpretation(\n",
    "        Name.patronymic.inflected()\n",
    "    ).optional()\n",
    ").interpretation(\n",
    "        Name\n",
    "),\n",
    "    rule(\n",
    "    gram('Name').repeatable().interpretation(\n",
    "        Name.last.inflected())\n",
    ").interpretation(\n",
    "        Name\n",
    "))\n",
    "\n",
    "PLACE = rule(\n",
    "    gram('Geox').interpretation(\n",
    "            Person.place.normalized()\n",
    ").optional()\n",
    ")\n",
    "\n",
    "PERSON = rule(\n",
    "    POSITION.interpretation(\n",
    "        Person.position.normalized()\n",
    "    ),\n",
    "    PLACE,\n",
    "    NAME.interpretation(\n",
    "        Person.name\n",
    "    )\n",
    ").interpretation(\n",
    "    Person\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = Parser(PERSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "\n",
    "for sent in sents:\n",
    "    for match in parser.findall(sent):\n",
    "        matches.append(match.fact)\n",
    "\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MorphToken('премьер',\n",
       "            [0, 7),\n",
       "            'RU',\n",
       "            [Form('премьер', Grams(NOUN,anim,masc,nomn,sing)),\n",
       "             Form('премьера', Grams(NOUN,femn,gent,inan,plur))]),\n",
       " Token('-', [7, 8), 'PUNCT'),\n",
       " MorphToken('министр',\n",
       "            [8, 15),\n",
       "            'RU',\n",
       "            [Form('министр', Grams(NOUN,anim,masc,nomn,sing))]),\n",
       " MorphToken('России',\n",
       "            [16, 22),\n",
       "            'RU',\n",
       "            [Form('россия', Grams(Geox,NOUN,Sgtm,femn,gent,inan,sing)),\n",
       "             Form('россия', Grams(Geox,NOUN,Sgtm,femn,inan,loct,sing)),\n",
       "             Form('россия', Grams(Geox,NOUN,Sgtm,datv,femn,inan,sing))]),\n",
       " MorphToken('Дмитрий',\n",
       "            [23, 30),\n",
       "            'RU',\n",
       "            [Form('дмитрий', Grams(NOUN,Name,anim,masc,nomn,sing)),\n",
       "             Form('дмитрия', Grams(NOUN,Name,anim,femn,gent,plur)),\n",
       "             Form('дмитрия', Grams(NOUN,Name,accs,anim,femn,plur))]),\n",
       " MorphToken('Медведев',\n",
       "            [31, 39),\n",
       "            'RU',\n",
       "            [Form('медведев', Grams(NOUN,Sgtm,Surn,anim,masc,nomn,sing))])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer('премьер-министр России Дмитрий Медведев'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
